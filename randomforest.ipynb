{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waiting for my mind to have breakdown once the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for my new anymore little bit not of just and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new year feeling there else depressed last eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for my to have the new feeling know about anyo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to the new year in start and into great myself...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text data  Label\n",
       "0  waiting for my mind to have breakdown once the...      1\n",
       "1  for my new anymore little bit not of just and ...      1\n",
       "2  new year feeling there else depressed last eve...      1\n",
       "3  for my to have the new feeling know about anyo...      1\n",
       "4  to the new year in start and into great myself...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('augmented_dataset1.csv')\n",
    "df=df[['Text data','Label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text data'], df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorization\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2560540997.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    glove_file = 'C:\\Users\\sreevishak\\Desktop\\DUK\\glove.6B\\glove.6B.100d.txt'\u001b[0m\n\u001b[1;37m                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GloVe embeddings\n",
    "glove_file = 'C:\\Users\\sreevishak\\Desktop\\DUK\\glove.6B\\glove.6B.100d.txt'\n",
    "word_vectors = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        word_vectors[word] = vector\n",
    "\n",
    "# Define a function to map words to GloVe embeddings\n",
    "def map_word_to_glove(word):\n",
    "    return word_vectors.get(word, np.zeros(100))  # Return zero vector for out-of-vocabulary words\n",
    "\n",
    "# Create document embeddings\n",
    "def create_document_embedding(doc):\n",
    "    words = doc.split()\n",
    "    word_embeddings = [map_word_to_glove(word) for word in words]\n",
    "    doc_embedding = np.mean(word_embeddings, axis=0)  # Average word embeddings\n",
    "    return doc_embedding\n",
    "# Create document embeddings for training and testing data\n",
    "X_train_glove = np.array([create_document_embedding(doc) for doc in X_train])\n",
    "X_test_glove = np.array([create_document_embedding(doc) for doc in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest Models\n",
    "rf_tfidf = RandomForestClassifier(random_state=42)\n",
    "rf_count = RandomForestClassifier(random_state=42)\n",
    "rf_w2v = RandomForestClassifier(random_state=42)\n",
    "rf_glove = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_tfidf.fit(X_train_tfidf, y_train)\n",
    "rf_count.fit(X_train_count, y_train)\n",
    "rf_w2v.fit(X_train_w2v, y_train)\n",
    "rf_glove.fit(X_train_glove,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: 0.9512735326688815\n",
      "TF-IDF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1245\n",
      "           1       0.90      0.95      0.93      1196\n",
      "           2       0.99      0.97      0.98      1171\n",
      "\n",
      "    accuracy                           0.95      3612\n",
      "   macro avg       0.95      0.95      0.95      3612\n",
      "weighted avg       0.95      0.95      0.95      3612\n",
      "\n",
      "Count Vectorization Accuracy: 0.9584717607973422\n",
      "Count Vectorization Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1245\n",
      "           1       0.91      0.97      0.94      1196\n",
      "           2       1.00      0.97      0.98      1171\n",
      "\n",
      "    accuracy                           0.96      3612\n",
      "   macro avg       0.96      0.96      0.96      3612\n",
      "weighted avg       0.96      0.96      0.96      3612\n",
      "\n",
      "Word2Vec Accuracy: 0.3241971207087486\n",
      "Word2Vec Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1245\n",
      "           1       0.00      0.00      0.00      1196\n",
      "           2       0.32      1.00      0.49      1171\n",
      "\n",
      "    accuracy                           0.32      3612\n",
      "   macro avg       0.11      0.33      0.16      3612\n",
      "weighted avg       0.11      0.32      0.16      3612\n",
      "\n",
      "glove accuracy: 0.9457364341085271\n",
      "glove classfication report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1245\n",
      "           1       0.92      0.93      0.93      1196\n",
      "           2       0.98      0.97      0.97      1171\n",
      "\n",
      "    accuracy                           0.95      3612\n",
      "   macro avg       0.95      0.95      0.95      3612\n",
      "weighted avg       0.95      0.95      0.95      3612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sreevishak/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sreevishak/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sreevishak/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions and Evaluate\n",
    "y_pred_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
    "y_pred_count = rf_count.predict(X_test_count)\n",
    "y_pred_w2v = rf_w2v.predict(X_test_W2V)\n",
    "y_pred_glove=rf_glove.predict(X_test_glove)\n",
    "\n",
    "\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "accuracy_count = accuracy_score(y_test, y_pred_count)\n",
    "accuracy_w2v = accuracy_score(y_test, y_pred_w2v)\n",
    "accuracy_glove=accuracy_score(y_test,y_pred_glove)\n",
    "\n",
    "\n",
    "report_tfidf = classification_report(y_test, y_pred_tfidf)\n",
    "report_count = classification_report(y_test, y_pred_count)\n",
    "report_w2v = classification_report(y_test, y_pred_w2v)\n",
    "report_glove=classification_report(y_test,y_pred_glove)\n",
    "\n",
    "print(f'TF-IDF Accuracy: {accuracy_tfidf}')\n",
    "print('TF-IDF Classification Report:')\n",
    "print(report_tfidf)\n",
    "\n",
    "print(f'Count Vectorization Accuracy: {accuracy_count}')\n",
    "print('Count Vectorization Classification Report:')\n",
    "print(report_count)\n",
    "\n",
    "print(f'Word2Vec Accuracy: {accuracy_w2v}')\n",
    "print('Word2Vec Classification Report:')\n",
    "print(report_w2v)\n",
    "\n",
    "print(f\"glove accuracy: {accuracy_glove}\")\n",
    "print('glove classfication report:')\n",
    "print(report_glove)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
