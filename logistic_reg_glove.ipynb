{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import string\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import gensim.downloader as api\n","from gensim.models import KeyedVectors"],"metadata":{"id":"rWvOVdnZf7Kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"graKMlOGhNOi","executionInfo":{"status":"ok","timestamp":1722205199926,"user_tz":-330,"elapsed":22916,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"8f4ac42a-1002-4c35-8c89-ed0d29e2451b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df=pd.read_csv('/content/drive/MyDrive/MINI PROJECT/DATASET/augmented_dataset1.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"GT_7tzHLhZS8","executionInfo":{"status":"ok","timestamp":1718700935930,"user_tz":-330,"elapsed":630,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"f5c46825-35d9-4c9b-e1d4-498c5c1a1cb9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PID                                          Text data  Label\n","0    0  waiting for my mind to have breakdown once the...      1\n","1    1  for my new anymore little bit not of just and ...      1\n","2    2  new year feeling there else depressed last eve...      1\n","3    3  for my to have the new feeling know about anyo...      1\n","4    4  to the new year in start and into great myself...      1"],"text/html":["\n","  <div id=\"df-11dec242-d6bb-4ba1-b29d-32c9efae0e60\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PID</th>\n","      <th>Text data</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>waiting for my mind to have breakdown once the...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>for my new anymore little bit not of just and ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>new year feeling there else depressed last eve...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>for my to have the new feeling know about anyo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>to the new year in start and into great myself...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11dec242-d6bb-4ba1-b29d-32c9efae0e60')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-11dec242-d6bb-4ba1-b29d-32c9efae0e60 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-11dec242-d6bb-4ba1-b29d-32c9efae0e60');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-eee1c4a0-69d9-40a6-8418-495ee7da777b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eee1c4a0-69d9-40a6-8418-495ee7da777b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-eee1c4a0-69d9-40a6-8418-495ee7da777b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 18057,\n  \"fields\": [\n    {\n      \"column\": \"PID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5212,\n        \"min\": 0,\n        \"max\": 18056,\n        \"num_unique_values\": 18057,\n        \"samples\": [\n          8279,\n          17407,\n          13457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text data\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5456,\n        \"samples\": [\n          \"buzzed pricey dabbled photo crevice displayed neighbour massage fuelled jon contracted pleading gynaecologist russian heavenly sanctuary dj izack crotch insistent buzz insisted stalker dale sam trained lesbians inseparable beth provocative mesh reinforced bled retaliate cellar mike andrew cooler bearably jessica befriended buildings partly legged pebbles esl appreciates attain russia expand yard snippets notebook angst socialgeneral rescue kindly basketball artistic incidents poses subsided sketchbooks ordeal crossed ecstasy penis attended playground satisfy minimal hindsight editing bottles collection emo photography salary professor rocks tinder teaching transferred triggering slut glanced pulled lyrics letter excelled toronto precious artistically recess straw crack session upsetting albeit rope std childish excites fashion block strict refused pop rumours volunteer photographer flourishing update proceeded closet poetry utter wrenching outcast uncertainty design graphic scraping upstairs hidden hung developing consistently stated dates carpet warm overdosing virginity phase behaviour water roll binge lasts wore heavily communication medicine portfolio pants lift roommates lab canada aspect kissing quietly kindness agreed tiny comfortable ordinary closure overly establishing habit cleared intentions discovered tour example honour boat result span plummeted speaking arrived rave drives attempts lasted continued meeting department education blurry begged gifts factor knowledge upon graduate teachers cat elementary children teacher lesson bullied onto fully doubting weren road kiss scene basis bullying cheated teenager teen minor involved opened deepest romantic movies increased difficult marks skipping swore chair photos ugly wedding disorder showered coke downtown tries destructive gather activity skip calm search coworkers blow amount slept brushed cries free early wine complete motivated pills nagging numerous minute dick attend men attention fast handle dangerous distributed wreck finish idiot bet occasionally woman clean shameful forgive words along truth walked pointed popular acne skinny attempted pushing hand attempt shy front cloud suffer friendship smoke girls met growing weed mainly hanging killed played aren exact included partner non boys bought word seemed selfish worry cool purpose whether middle wearing daily beautiful evening pass offer blur falling laughed clearly describe happens interest check calling show frequent solid anxious continuing exercising fit final haven forced text hang drugs meet shut bar sleeping chat easily suck borderline hasn yes laugh fighting second sucked birthday realize none ending bathroom terrified sex letting advice medication effort degree career brain looked throw course choice trouble mentally warning ago driving outside sexual realized several although art relationships helped push couple kick numb inside guy moving answer split lets drop group thrown dating throughout girl dated style parties trapped taking soon many th excited human grade sober high hurt come doomed brought nor knew fall physically believe doesn age didn began took man spotted rest floor apartment parent lived matter okay lots such mad saying short program engineering during company bring grew passing liked reached food instead forget managed apart quickly cut attached episode says break call phone forward thank regular usually drunk drinking place putting went quite stayed came remember crazy won conversation too speak idea used parents working getting fun their ones loved wanted tv motivation seem huge top house kids world read let truly finding write writing use given guys turns sitting partying gone eventually threw drive gave thoughts times stuff home move often allowed wouldn drink half today sometime wanting alcohol bottle awful pull dad well stand couldn each sad why stop bottom marriage finally an boyfriend yet ve officially himself drastically may hands situation anxiety help kind became makes somehow language occasions those done order moment nothing over constantly who angry apparently found extremely having cry party everyone body starting completely take really us much pretty other own trying offered stay sure work off car afford next felt almost which sleep day turned together spent rent pay classes through first our another able his lost away gets mom stopped morning every due twice different two put relationship abusive long see therapy hours despite older teenage followed how as close very her she while living make hard say around when going dark than maybe interesting worse probably end born job point what night right room spend tell are these school alone mine myself did good by months ever thing think had heart could music listening after great bad everything you would they am has them more someone scared always head experience already find can people since made also serious again started things told never depression luckily reason some doing talking old ill life real one no been anything do so learned english from story your on be will want all lot asking with then happy even office into get im years normal way it just month where until wasn crying down start not something or time days few in back little but anyone about don anymore there isn feeling year new once mind reported options replies deleting option nowhere college suicide posting everytime asked literally were risk upset ended before week got we him said nobody out at person friends trust still he friend best me post thought talk only ive here because like is this dont if feel and now was up broke of tried last being go that else know the have to my for\",\n          \"effected lives how are by you depression your in anxietydepression basis daily suicidal removed thoughts having on\",\n          \"for my mind to have the new feeling there anymore don about else little that ll go back being in time or not any of crying entire was just it way and feel normal get even with this shit lot is all like be from so do anything been only no one real life me friend some reason never family made since can friends at out social them has am everything bad wish could had think thing ever by good myself room mum around make alive as fuck away almost off sure staying losing related starting hate cry panic attack angry who watching games anxiety ve why videos stuff least give understands world kids top huge playing used complicated looking exist barely age come keeping kid gotten meant taking likes college whatever fear worry whenever isolate syndrome teen picture checking relatives horror hormones homeschooled asperger undo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")\n","stop_words = nlp.Defaults.stop_words\n","punctuations = string.punctuation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bg8a8NJOhq5-","executionInfo":{"status":"ok","timestamp":1718700938391,"user_tz":-330,"elapsed":716,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"a8a5de21-5757-4b76-991f-8d082cb509b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n"]}]},{"cell_type":"code","source":["model=api.load('glove-twitter-100')"],"metadata":{"id":"zXRDsYY_khxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def spacy_tokenizer(sentence):\n","    # Creating our token object, which is used to create documents with linguistic annotations.\n","    doc = nlp(sentence)\n","\n","    # Lemmatizing each token and converting each token into lowercase\n","    mytokens = [word.lemma_.lower().strip() for word in doc]\n","\n","    # Removing stop words and punctuations\n","    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n","\n","    # Return preprocessed list of tokens\n","    return mytokens"],"metadata":{"id":"asotqrR4s95T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['tokens'] = df['Text data'].apply(spacy_tokenizer)\n"],"metadata":{"id":"dDnOI0EdtMAQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate document vectors for each document\n","def document_vector(tokens, embeddings, dim):\n","    token_vectors = [embeddings[token] for token in tokens if token in embeddings]\n","    if not token_vectors:\n","        return np.zeros(dim)\n","    return np.mean(token_vectors, axis=0)"],"metadata":{"id":"VXskrkpIws3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['vec'] = df['tokens'].apply(lambda x: document_vector(x, model, model.vector_size))"],"metadata":{"id":"0rsbnMrRxXtG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare features (X) and labels (y)\n","X = np.vstack(df['vec'])\n","y = df['Label']"],"metadata":{"id":"eSTvHpUnyFEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)"],"metadata":{"id":"UlV3_YONyKvy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_pipeline_lr = Pipeline([\n","    ('lr', LogisticRegression(max_iter=1000, random_state=1))  # Increase max_iter if needed\n","])\n"],"metadata":{"id":"70NvmtLRyMFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","model_pipeline_lr.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_lr = model_pipeline_lr.predict(X_test)\n"],"metadata":{"id":"XIDgEyXxyRvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","accuracy_lr = accuracy_score(y_test, y_pred_lr)\n","precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n","recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n","f1_score_lr = f1_score(y_test, y_pred_lr, average='weighted')\n","classification_report_lr = classification_report(y_test, y_pred_lr)\n","\n","# Print evaluation metrics\n","print(\"Evaluation Metrics for Logistic Regression Model\")\n","print(\"------------------------------------------------\")\n","print(f\"Accuracy: {accuracy_lr:.4f}\")\n","print(f\"Precision: {precision_lr:.4f}\")\n","print(f\"Recall: {recall_lr:.4f}\")\n","print(f\"F1-score: {f1_score_lr:.4f}\")\n","print(\"Classification Report:\")\n","print(classification_report_lr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIqmu6royUiL","executionInfo":{"status":"ok","timestamp":1718704756483,"user_tz":-330,"elapsed":537,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"cc4d3402-2c23-45f4-bae4-00d5885e9045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation Metrics for Logistic Regression Model\n","------------------------------------------------\n","Accuracy: 0.6556\n","Precision: 0.6563\n","Recall: 0.6556\n","F1-score: 0.6543\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.65      0.67      1194\n","           1       0.64      0.58      0.61      1236\n","           2       0.64      0.74      0.69      1182\n","\n","    accuracy                           0.66      3612\n","   macro avg       0.66      0.66      0.65      3612\n","weighted avg       0.66      0.66      0.65      3612\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import string\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import gensim.downloader as api\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/MINI PROJECT/DATASET/augmented_dataset1.csv\")\n","\n","# Load SpaCy model and define stop words and punctuations\n","nlp = spacy.load(\"en_core_web_sm\")\n","stop_words = nlp.Defaults.stop_words\n","punctuations = string.punctuation\n","\n","# Load pre-trained GloVe embeddings\n","model = api.load('glove-twitter-100')\n","\n","# Function to tokenize and preprocess text\n","def spacy_tokenizer(sentence):\n","    doc = nlp(sentence)\n","    mytokens = [word.lemma_.lower().strip() for word in doc]\n","    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n","    return mytokens\n","\n","# Apply tokenization to each row in 'Text data' column\n","df['tokens'] = df['Text data'].apply(spacy_tokenizer)\n","\n","# Generate document vectors for each document\n","def document_vector(tokens, embeddings, dim):\n","    token_vectors = [embeddings[token] for token in tokens if token in embeddings]\n","    if not token_vectors:\n","        return np.zeros(dim)\n","    return np.mean(token_vectors, axis=0)\n","\n","df['vec'] = df['tokens'].apply(lambda x: document_vector(x, model, model.vector_size))\n","\n","# Prepare features (X) and labels (y)\n","X = np.vstack(df['vec'])\n","y = df['Label']\n","\n","# Normalize features for Naive Bayes\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, train_size=0.8, random_state=1)\n","\n","# Initialize and train Naive Bayes model\n","naive_bayes = MultinomialNB()\n","naive_bayes.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_nb = naive_bayes.predict(X_test)\n","\n","# Evaluate the model\n","accuracy_nb = accuracy_score(y_test, y_pred_nb)\n","precision_nb = precision_score(y_test, y_pred_nb, average='weighted')\n","recall_nb = recall_score(y_test, y_pred_nb, average='weighted')\n","f1_score_nb = f1_score(y_test, y_pred_nb, average='weighted')\n","classification_report_nb = classification_report(y_test, y_pred_nb)\n","\n","# Print evaluation metrics\n","print(\"Evaluation Metrics for Naive Bayes Model\")\n","print(\"------------------------------------------------\")\n","print(f\"Accuracy: {accuracy_nb:.4f}\")\n","print(f\"Precision: {precision_nb:.4f}\")\n","print(f\"Recall: {recall_nb:.4f}\")\n","print(f\"F1-score: {f1_score_nb:.4f}\")\n","print(\"Classification Report:\")\n","print(classification_report_nb)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7RsLmUSbSh4","executionInfo":{"status":"ok","timestamp":1722205839259,"user_tz":-330,"elapsed":629065,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"}},"outputId":"9751066e-b4b1-4edb-9b1e-48395802ecef"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 387.1/387.1MB downloaded\n","Evaluation Metrics for Naive Bayes Model\n","------------------------------------------------\n","Accuracy: 0.5648\n","Precision: 0.5774\n","Recall: 0.5648\n","F1-score: 0.5610\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.49      0.56      1194\n","           1       0.57      0.49      0.52      1236\n","           2       0.52      0.72      0.60      1182\n","\n","    accuracy                           0.56      3612\n","   macro avg       0.58      0.57      0.56      3612\n","weighted avg       0.58      0.56      0.56      3612\n","\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}