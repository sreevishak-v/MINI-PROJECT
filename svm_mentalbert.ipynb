{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rEszaCIfh-Tw"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38822,"status":"ok","timestamp":1722190336650,"user":{"displayName":"SREEVISHAK V","userId":"04180199107471874403"},"user_tz":-330},"id":"eHsuAGrZimjd","outputId":"1e65991e-2708-493a-8f23-62bdf18070d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bYncgUPiiyAZ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uJWqxfasi0BH","outputId":"92fe65bc-20ae-48dd-9293-73affebeb9ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["         PID                                          Text data  Label\n","18052  18052  ov trudging remembe dehydrated pregame adays d...      2\n","18053  18053  exacerbate floated prescribes wonky combo fibr...      2\n","18054  18054  voice heavy terrible awake help need night its...      2\n","18055  18055  wonder doesn smile face hate what right can be...      2\n","18056  18056  redacted overshare detail center colleges room...      2\n","    PID                                          Text data  Label\n","0  2868  my to have about being in not any way and im i...      1\n","1  5924  for to the know but that in few of broke up wa...      1\n","2  3764  new being same dont this shit will so me think...      1\n","3  4144  for my to have once the new year there anymore...      1\n","4  2780  for my to have the new year anymore about but ...      1\n"]}],"source":["df = pd.read_csv('/content/drive/MyDrive/MINI PROJECT/DATASET/augmented_dataset1.csv')\n","print(df.tail())\n","\n","df = pd.concat([\n","    df[df['Label'] == 1].sample(n=300, random_state=42),\n","    df[df['Label'] == 0].sample(n=300, random_state=42),\n","    df[df['Label'] == 2].sample(n=300, random_state=42)\n","])\n","\n","# Reset index to avoid indexing issues\n","df = df.reset_index(drop=True)\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pd1ha6aCi1aH","outputId":"29a86e45-133c-41dd-c07d-4fcd5085c8e0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["token = \"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\"\n","tokenizer = AutoTokenizer.from_pretrained(\"mental/mental-bert-base-uncased\", use_auth_token=token)\n","model = AutoModel.from_pretrained(\"mental/mental-bert-base-uncased\", use_auth_token=token)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5kzh98dKi5ez"},"outputs":[],"source":["def get_bert_features(text_batch, model, tokenizer):\n","    encoded_inputs = tokenizer.batch_encode_plus(\n","        text_batch,\n","        add_special_tokens=True,\n","        max_length=128,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    input_ids = encoded_inputs['input_ids']\n","    attention_mask = encoded_inputs['attention_mask']\n","\n","    with torch.no_grad():\n","        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n","\n","    features = last_hidden_states[0][:, 0, :].numpy()\n","    return features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Uq_TDhshi7mn"},"outputs":[],"source":["batch_size = 100\n","features_list = []\n","for i in range(0, df.shape[0], batch_size):\n","    text_batch = df['Text data'].iloc[i:i+batch_size].tolist()\n","    batch_features = get_bert_features(text_batch, model, tokenizer)\n","    features_list.append(batch_features)\n","\n","# Concatenate all features\n","features = np.concatenate(features_list, axis=0)\n","\n","# Labels\n","labels = df['Label'].values\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tILXXOXZi9NR"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fcwFHB3xi-wJ","outputId":"3fa7c0ba-13d2-45ca-f1e6-fa55133ae006"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.76      0.77        67\n","           1       0.77      0.77      0.77        60\n","           2       0.76      0.77      0.77        53\n","\n","    accuracy                           0.77       180\n","   macro avg       0.77      0.77      0.77       180\n","weighted avg       0.77      0.77      0.77       180\n","\n","Accuracy: 0.7667\n"]}],"source":["svm_clf = SVC(kernel='linear', random_state=42)\n","svm_clf.fit(x_train, y_train)\n","\n","pred = svm_clf.predict(x_test)\n","\n","# Print classification report\n","print(classification_report(y_test, pred))\n","\n","# Calculate and print accuracy\n","accuracy = accuracy_score(y_test, pred)\n","print(f'Accuracy: {accuracy:.4f}')\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}